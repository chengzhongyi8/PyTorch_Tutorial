{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度学习介绍\n",
    "### 人工智能\n",
    "* 关于人工智能的定义有很多说法，我最喜欢的一个是，人工智能是指通常由人来完成的智能任务的自动化。\n",
    "\n",
    "### 机器学习\n",
    "* 机器学习是人工智能的一个子领域，也是实现人工智能的一种途径。与传统的通过对规则进行硬编码的符号人工智能不同，机器学习注重算法的设计，让计算机能够自动地从数据中“学习”规则，并利用规则对未知数据进行预测，如下图所示。\n",
    "\n",
    "<img src=\"./Images/机器学习vs经典编程.jpg\" width=350, heigth=300>\n",
    "\n",
    "* 机器学习可以分为五大类：\n",
    "    1. **监督学习：** 从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求是有**输入和输出**，也可以说是**特征和标签**。训练集中的标签是人标注的。常见的监督学习算法包括**回归与分类**。\n",
    "    2. **无监督学习：** 无监督学习与监督学习相比，训练集没有人为标注的结果。常见的无监督学习算法有聚类等。\n",
    "    3. **半监督学习：** 这是一种介于监督学习和无监督学习之间的方法。\n",
    "    4. **迁移学习：** 将已经训练好的模型参数迁移到新的模型来帮助新模型训练数据集。\n",
    "    5. **增强学习：** 通过观察周围环境来学习。每个动作都会对环境有所影响，学习对象根据观察到的周围环境的反馈来做出判断。\n",
    "\n",
    "### 深度学习\n",
    "* 深度学习的最初版本是人工神经网络，这是机器学习的一个分支，其试图模拟人脑，通过更加复杂的结构自动提取数据特征。在机器学习领域有这样一句话**“数据与特征决定机器学习的上限，而不同的模型与算法只是逼近上限的程度不一样而已”**，说明特征非常重要，这在一般的机器学习方法中也是非常费时费力的，而深度学习能将这一过程自动化。以上三者的关系如下图所示。\n",
    "\n",
    "<img src=\"./Images/relation.jpg\" width=300, heigth=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度学习框架\n",
    "* 在早期，人们需要C++和CUDA的专业知识来实现深度学习算法。现在随着很多公司将它们的深度学习框架开源，使得那些具有脚本语言知识（如Python）的人，也可以开始构建和使用深度学习算法。现在，常用的深度学习框架如下图。目前，最流行的框架有三种，Tensorflow, Keras, PyTorch。\n",
    "\n",
    "<img src=\"./Images/DL framework.png\", width=450, heigth=450> \n",
    "<img src=\"./Images/framework score.png\", width=480, heigth=480> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch介绍\n",
    "* PyTorch 是由 Torch7 团队开源的，这也是Facebook 的 AI 研究团队发布了一个 Python 工具包，据该项目官网介绍，是一个 Python 优先的深度学习框架，能够在强大的 GPU 加速基础上实现张量和动态神经网络。\n",
    "    - [官网](http://pytorch.org/)\n",
    "    - [Github](https://github.com/pytorch/pytorch)\n",
    "    - [官方入门教材](https://pytorch.org/deep-learning-with-pytorch-thank-you)\n",
    "\n",
    "* 目前除了 Facebook 之外，也有大量的机构正在使用 PyTorch\n",
    "\n",
    "![](https://ws2.sinaimg.cn/large/006tNc79ly1fmebl3ayfij30kk0c2aac.jpg)\n",
    "* PyTorch 提供了两种高层面的功能：\n",
    "    1. 使用强大的 GPU 加速的 Tensor 计算（类似 numpy）\n",
    "    2. 构建于基于 autograd 系统的深度神经网络\n",
    "* 所以使用 PyTorch 的原因通常有两个：\n",
    "    1. 作为 numpy 的替代，以便使用强大的 GPU 加速；\n",
    "    2.  将其作为一个能提供最大灵活性和速度的深度学习研究平台\n",
    "* <p>让 PyTorch 越来越受欢迎的是它的**易用性和简单性**。不同于其他大多数使用静态计算图的深度学习框架，**PyTorch使用动态图计算**，因此在构建复杂架构时可以有更高的灵活性。\n",
    "\n",
    "* <p>**PyTorch 坚持Python 优先**，它不是简单地在整体 C++ 框架上绑定 Python，他深入构建在 Python 之上，你可以像使用 numpy/scipy/scikit-learn 那样轻松地使用 PyTorch，也可以用你喜欢的库和包在 PyTorch 中编写新的神经网络层，尽量让你不用重新发明轮子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch 安装\n",
    "* PyTorch 安装非常简单，按照官网指示即可。\n",
    "\n",
    "<img src=\"./Images/pytorch install.jpg\", width=600, heigth=480> \n",
    "\n",
    "* **温馨提示：** 在自己电脑上安装什么版本都行，但是在4楼 GPU 服务器上安装时，考虑到我们用的是 CUDA 9.0，所以不要使用太新的版本。我用的是** Python 3.6 + PyTorch 1.1.0 + TorchVision 0.3.0**，仅供参考。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 动态图介绍\n",
    "\n",
    "* <p>目前神经网络框架分为静态图框架和动态图框架，PyTorch 和 TensorFlow、Caffe 等框架最大的区别就是他们拥有不同的计算图表现形式。 TensorFlow 使用静态图，这意味着我们先定义计算图，然后不断使用它，而在 PyTorch 中，每次都会重新构建一个新的计算图。\n",
    "* <p>对于使用者来说，两种形式的计算图有着非常大的区别，同时静态图和动态图都有他们各自的优点，**比如动态图比较方便debug**，使用者能够用任何他们喜欢的方式进行debug，同时非常直观，而**静态图是通过先定义后运行的方式，之后再次运行的时候就不再需要重新构建计算图，所以速度会比动态图更快**。\n",
    "\n",
    "* <p>PyTorch 官方教材对静态图和动态图给出如下对比：\n",
    "\n",
    "<img src=\"./Images/graph.png\", width=900, heigth=700> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比静态图与动态度\n",
    "#### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zq\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "first_counter = tf.constant(0) ## 定义一个常量tensor\n",
    "second_counter = tf.constant(10)\n",
    "\n",
    "def cond(first_counter, second_counter, *args):\n",
    "    return first_counter < second_counter\n",
    "\n",
    "def body(first_counter, second_counter):\n",
    "    first_counter = tf.add(first_counter, 2)\n",
    "    second_counter = tf.add(second_counter, 1)\n",
    "    return first_counter, second_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1, c2 = tf.while_loop(cond, body, [first_counter, second_counter])  ## 构建静态图，在cond满足的时候，执行body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:  ## 构建一个会话，在会话中执行计算图\n",
    "    counter_1_res, counter_2_res = sess.run([c1, c2])\n",
    "\n",
    "print(counter_1_res)\n",
    "print(counter_2_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 可以看到 TensorFlow 需要将整个图构建成静态的，换句话说，每次运行的时候图都是一样的，是不能够改变的，所以不能直接使用 Python 的 while 循环语句，需要使用辅助函数 tf.while_loop 写成 TensorFlow 内部的形式。\n",
    "\n",
    "* 这是非常反直觉的，学习成本也是比较高的\n",
    "\n",
    "* 下面来看看 PyTorch 的动态图机制，这使得我们能够使用 Python 的 while 写循环，非常方便"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "first_counter = torch.Tensor([0]) ## 定义一个常量tensor\n",
    "second_counter = torch.Tensor([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while (first_counter < second_counter):  ## 直接使用tensor运算，一边构建图，一边就在运算，就是所谓的动态图\n",
    "    first_counter += 2\n",
    "    second_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20.])\n",
      "tensor([20.])\n"
     ]
    }
   ],
   "source": [
    "print(first_counter)\n",
    "print(second_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 可以看到 PyTorch 的写法跟 Python 的写法是完全一致的，没有任何额外的学习成本，所以动态图的方式更加简单且直观。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
